import unicodedata
import csv
import re
import os


def _norm_ws(t: str) -> str:
    """Aplatit juste les espaces (sans NFKC)."""
    return re.sub(r"\s+", " ", t).strip()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Fallback regex
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# verifier si on a pas casser qq chose
"""RE_AVOCAT = re.compile(
    r"(?i)"
    r"(?:ma[Ã®i]tre|me)?\s*"
    r"(?P<nom>[A-ZÃ‰ÃˆÃ€Ã‚ÃŠÃÃ”Ã›Ã‡][a-zÃ -Ã¶Ã¸-Ã¿'â€™-]+"
    r"(?:\s+[A-ZÃ‰ÃˆÃ€Ã‚ÃŠÃÃ”Ã›Ã‡][a-zÃ -Ã¶Ã¸-Ã¿'â€™-]+"
    r"|\s+[A-ZÃ‰ÃˆÃ€Ã‚ÃŠÃÃ”Ã›Ã‡-]{2,}){1,3})"
    r"\s*,?\s*avocat(?:e)?\b\s*,?"
)"""

RE_AVOCAT = re.compile(
    r"""(?ix)               # i=ignorecase, x=verbose pour lisibilitÃ©
    (?:ma[Ã®i]tre|me)?\s*
    (?P<nom>
        (?:[A-ZÃ‰ÃˆÃ€Ã‚ÃŠÃÃ”Ã›Ã‡][a-zÃ -Ã¶Ã¸-Ã¿'â€™\-]+|[A-ZÃ‰ÃˆÃ€Ã‚ÃŠÃÃ”Ã›Ã‡\-]{2,})
        (?:\s+|,\s*)
        (?:[A-ZÃ‰ÃˆÃ€Ã‚ÃŠÃÃ”Ã›Ã‡][a-zÃ -Ã¶Ã¸-Ã¿'â€™\-]+|[A-ZÃ‰ÃˆÃ€Ã‚ÃŠÃÃ”Ã›Ã‡\-]{2,})
        (?:
            (?:\s+|,\s*)
            (?:[A-ZÃ‰ÃˆÃ€Ã‚ÃŠÃÃ”Ã›Ã‡][a-zÃ -Ã¶Ã¸-Ã¿'â€™\-]+|[A-ZÃ‰ÃˆÃ€Ã‚ÃŠÃÃ”Ã›Ã‡\-]{2,})
        ){0,2}
    )
    \s*,?\s*avocat(?:e)?\b
    """,
    re.VERBOSE
)



RE_CABINET = re.compile(
    r"(?i)"
    r"(?P<nom>[A-ZÃ‰ÃˆÃ€Ã‚ÃŠÃÃ”Ã›Ã‡][a-zÃ -Ã¶Ã¸-Ã¿'â€™-]+"
    r"(?:\s+[A-ZÃ‰ÃˆÃ€Ã‚ÃŠÃÃ”Ã›Ã‡][a-zÃ -Ã¶Ã¸-Ã¿'â€™-]+"
    r"|\s+[A-ZÃ‰ÃˆÃ€Ã‚ÃŠÃÃ”Ã›Ã‡-]{2,}){1,3})"
    r"\s*,?\s*dont\s+(?:le\s+cabinet|les\s+bureaux)\s+(?:est|sont)\s+(?:sis|Ã©tablis?)"
)

# RE_ADMIN corrigÃ© pour rÃ©cupÃ©rer toutes les occurrences sans avaler trop loin
RE_ADMIN = re.compile(
    # 1) le NOM (âš ï¸ pas d'IGNORECASE ici)
    r"(?P<nom>[A-ZÃ‰ÃˆÃ€Ã‚ÃŠÃÃ”Ã›Ã‡][a-zÃ -Ã¶Ã¸-Ã¿'â€™-]+"
    r"(?:\s+(?:[A-ZÃ‰ÃˆÃ€Ã‚ÃŠÃÃ”Ã›Ã‡][a-zÃ -Ã¶Ã¸-Ã¿'â€™-]+|[A-ZÃ‰ÃˆÃ€Ã‚ÃŠÃÃ”Ã›Ã‡-]{2,})){1,3})"
    # 2) micro-fenÃªtre optionnelle : pas de majuscule (Ã©vite d'avaler un autre nom)
    r"(?:\s*,?[^A-ZÃ‰ÃˆÃ€Ã‚ÃŠÃÃ”Ã›Ã‡]{0,70}?)?"
    # 3) la formule "a Ã©tÃ© dÃ©signÃ© ..." (en IGNORECASE uniquement ici)
    r"(?i:\ba\s+Ã©tÃ©\s+d[Ã©e]sign[Ã©e]\s+en\s+qualit[Ã©e]\s+d['â€™]administrateur(?:trice)?)"
)


def _extract_with_regex(text: str, pattern: re.Pattern) -> list[str]:
    txt = _norm_ws(text)
    out, seen = [], set()
    for m in pattern.finditer(txt):
        nom = re.sub(r"\s+", " ", m.group("nom").strip(" ,.;:()[]{}â€”â€“-"))
        if nom and nom not in seen:
            seen.add(nom)
            out.append(nom)
    return out


def extract_names_avocat(text: str) -> list[str]:
    return _extract_with_regex(text, RE_AVOCAT)


def extract_names_cabinet(text: str) -> list[str]:
    return _extract_with_regex(text, RE_CABINET)


def extract_names_admin(text: str) -> list[str]:
    return _extract_with_regex(text, RE_ADMIN)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Normalisation noms & variantes CSV
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def normaliser_nom(nom: str) -> str:
    nfkd_form = unicodedata.normalize('NFKD', nom)
    sans_accents = "".join(c for c in nfkd_form if not unicodedata.combining(c))
    nettoye = sans_accents.replace("'", "").replace(".", "").lower()
    return " ".join(nettoye.split())


def variantes_nom(nom: str) -> set:
    variantes = set()
    nom_norm = normaliser_nom(nom)
    variantes.add(nom_norm)

    parts = nom_norm.split()
    if len(parts) == 2:
        variantes.add(f"{parts[1]} {parts[0]}")
    if len(parts) > 2:
        variantes.add(f"{' '.join(parts[1:])} {parts[0]}")
    particules = {"de", "du", "la", "le", "van", "von", "der"}
    variantes.add(" ".join(p for p in parts if p not in particules))
    return variantes


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Nettoyage libellÃ©s (MaÃ®tre / par MaÃ®tre)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def nettoyer_prefixes_maitre(nom: str) -> str:
    """Retire 'MaÃ®tre' ou 'par MaÃ®tre' au dÃ©but, normalise espaces/ponctuation."""
    nom2 = re.sub(r"(?i)^(?:par\s+)?ma[Ã®i]tre\s+", "", nom)
    nom2 = re.sub(r"\s+", " ", nom2).strip(" ,.;:()[]{}â€”â€“-")
    return nom2


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Fonction principale â€” OPTION A Ã©largie
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def trouver_personne_dans_texte(texte: str, chemin_csv: str, mots_clefs: list) -> list[str]:
    texte_norm = normaliser_nom(_norm_ws(texte))
    mots_norm = [normaliser_nom(m.replace("+", " ")) for m in mots_clefs]
    trouves = set()

    noms_csv = []
    if os.path.exists(chemin_csv):
        with open(chemin_csv, mode='r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            noms_csv = [row["nom"].strip() for row in reader]

        # 1) recherche sur mots-clÃ©s Â±80 caractÃ¨res
        for mot_clef_norm in mots_norm:
            for m in re.finditer(re.escape(mot_clef_norm), texte_norm):
                pos = m.start()
                fenetre = texte_norm[max(0, pos - 300): pos + 300]
                for nom in noms_csv:
                    for variante in variantes_nom(nom):
                        if variante and variante in fenetre:
                            trouves.add(nom)
                            break
    else:
        print(" Fichier CSV introuvable.")

    # Si trouvÃ© via CSV â†’ on renvoie (on NE nettoie PAS, on suppose le CSV propre)
    if trouves:
        return sorted(trouves)

    # 2) Fallback indÃ©pendant : avocat + cabinet + administrateur
    candidats = (
        extract_names_avocat(texte)
        + extract_names_cabinet(texte)
        + extract_names_admin(texte)
    )

    # ğŸ”¹ Nettoyage 'MaÃ®tre' / 'par MaÃ®tre' + normalisation
    propres = []
    seen = set()
    for c in candidats:
        c2 = nettoyer_prefixes_maitre(c)
        if c2 and c2 not in seen:
            seen.add(c2)
            propres.append(c2)

    # Retourne les regex fallback avec un "role" pour les diffÃ©rencier
    return [{"nom": n, "role": "regex-fallback", "raw": n} for n in sorted(propres)]
